{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0511939",
   "metadata": {},
   "source": [
    "# Caption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a7592e5-ec9b-4cee-93a5-e549c1fccdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import pandas as pd\n",
    "import openai\n",
    "from time import sleep\n",
    "import os\n",
    "file_path = \"../../openai_key.txt\"\n",
    "\n",
    "with open(file_path, \"r\") as file:\n",
    "    key = file.read()\n",
    "openai.api_key = key\n",
    "import numpy as np\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cb47a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_questions_anwers(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": prompt}\n",
    "    ])\n",
    "    questions_answers = completion.choices[0].message.content\n",
    "    return questions_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7608597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_processing(caption):\n",
    "    remove_words =[\"in this image i can see \", \"in this image we can see \",  \"this is an image of \", \"a cartoon of \", \"simpson \", \"homer \", \"a cartoon of \", \"cartoon \", \"this is an image of \"]\n",
    "    for remove_word in remove_words:\n",
    "        caption = caption.replace(remove_word, \"\")\n",
    "    replaced_by_person_words = [\"duck\", \"bear\", \" character\"]\n",
    "    for word in replaced_by_person_words:\n",
    "        caption.replace(word, \"person\")\n",
    "    caption.replace(\"characters\", \"people\")\n",
    "    caption.replace(\"simpsons\", \"people\")\n",
    "    return caption + \". people skin is yellow.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "833a139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_pth(img):\n",
    "    ss = img[:3]\n",
    "    image_path = ss + \"/\" + img + \".jpg\"\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7513fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cases(string):\n",
    "    string = string.replace(\"For case\", \"Case\")\n",
    "    string = string.replace(\"For Case\", \"Case\")\n",
    "    string = string.replace(\":\\n\", \":\")\n",
    "    \n",
    "    cases = []\n",
    "    \n",
    "    # Split the string by 'Case' to separate each case\n",
    "    case_strings = string.split('Case ')[1:]\n",
    "    \n",
    "    for case_string in case_strings:\n",
    "        case = {}\n",
    "        \n",
    "        # Split the case string by newline character '\\n' to separate each question-answer pair\n",
    "        pairs = case_string.split('\\nQ:')[1:]\n",
    "        \n",
    "        case['questions'] = []\n",
    "        case['answers'] = []\n",
    "        case['topics'] = []\n",
    "        \n",
    "        for pair in pairs:\n",
    "            # Split the pair by 'Q:', 'A:', and 'Topic:' to extract the question, answer, and topic respectively\n",
    "            question, answer, topic = pair.split(' A:', 1)[0].strip(), pair.split(' A:', 1)[1].split(' Topic:', 1)[0].strip(), pair.split(' Topic:', 1)[1].strip()\n",
    "            \n",
    "            case['questions'].append(question)\n",
    "            case['answers'].append(answer)\n",
    "            case['topics'].append(topic)\n",
    "        \n",
    "        cases.append(case)\n",
    "    \n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b807d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt(sub_df, idx, requirement, start_time):\n",
    "    caption_1 = list(sub_df[\"caption_1\"])\n",
    "    caption_2 = list(sub_df[\"caption_2\"])\n",
    "    prompt = requirement\n",
    "    for i, (c1,c2) in enumerate(zip(caption_1, caption_2)):\n",
    "        prompt += f\"\\nCase {i+1}\\n\"\n",
    "        prompt += f\"Description 1: {c1}\\n\"\n",
    "        prompt += f\"Description 2: {c2}\\n\"\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            string_result = get_questions_anwers(prompt)\n",
    "            success = True\n",
    "        except:\n",
    "            print(\"retrying\")\n",
    "            sleep(5)\n",
    "    if (idx + 1) % 2 == 0:\n",
    "        print(\"-\"*50)\n",
    "        print(f\"Processing {((idx+1)*3)} captions\")\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(f\"running time: {round(elapsed_time, 0)} seconds\")\n",
    "    cases = extract_cases(string_result)\n",
    "    \n",
    "    return cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a164dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "requirement = \"You are given three cases with two different descriptions of an image each. \" + \\\n",
    "    \"You are required to ask 10 questions, their topics, and their answers based on the two descriptions for each case. \" + \\\n",
    "    \"The questions must be suitable for preschool students and should be about counting, reasoning, object detection, \" + \\\n",
    "    \"action recognition, attribute classification, comparative, spatial, or position. \" + \\\n",
    "    \"Morevoer, the type of question should be yes/no and open-end and the answer cannot be more than 3 word.\" + \\\n",
    "    \"\\ncase 0:\\n\" + \\\n",
    "    \"Description 1: a man is standing in front of a large screen that is turned on he is wearing a blue shirt andblue headphones he is also wearing a purple shirt and a purple vest there is a large mirror on the wall behind the man.\\n\" + \\\n",
    "    \"Description 2: a person is standing and he is wearing headphones on his head he is holding a microphone in his handhe is also wearing a blue tshirt and i can also see a microphone on the right side of the image there is a wall.\\n\" + \\\n",
    "    \"case 0:\\n\" + \\\n",
    "    \"Q:How many people are there? A:1 Topic:Counting.\\n\" + \\\n",
    "    \"Q:What is the man doing? A:Standing Topic:Action recognition.\\n\" + \\\n",
    "    \"Q:Is there a microphone? A:Yes Topic:Object detection.\\n\" + \\\n",
    "    \"Q:How many microphones? A:1 Topic:Counting.\\n\" + \\\n",
    "    \"Q:What color is the man's shirt? A:Blue Topic:Attribute classification.\\n\" + \\\n",
    "    \"Q:What is hanging on the wall? A:Mirror Topic:Object detection.\\n\" + \\\n",
    "    \"Q:What is he standing in front of? A:Screen Topic:Object detection.\\n\" + \\\n",
    "    \"Q:Is he taller than the mirror? A:Unknown Topic:Comparative.\\n\" + \\\n",
    "    \"Q:Where is the mirror hanging? A:Wall Topic:Position.\\n\" + \\\n",
    "    \"Q:What is the shape of the mirror? A:Unknown Topic:Attribute classification.\\n\" + \\\n",
    "    \"Q:How in the man feelining? A:Unknown Topic:Reasoning.\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0e3eb108-8680-4af6-87ef-2b7b65f9cf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given three cases with two different descriptions of an image each. You are required to ask 10 questions, their topics, and their answers based on the two descriptions for each case. The questions must be suitable for preschool students and should be about counting, reasoning, object detection, action recognition, attribute classification, comparative, spatial, or position. Morevoer, the type of question should be yes/no and open-end and the answer cannot be more than 3 word.\n",
      "case 0:\n",
      "Description 1: a man is standing in front of a large screen that is turned on he is wearing a blue shirt andblue headphones he is also wearing a purple shirt and a purple vest there is a large mirror on the wall behind the man.\n",
      "Description 2: a person is standing and he is wearing headphones on his head he is holding a microphone in his handhe is also wearing a blue tshirt and i can also see a microphone on the right side of the image there is a wall.\n",
      "case 0:\n",
      "Q:How many people are there? A:1 Topic:Counting.\n",
      "Q:What is the man doing? A:Standing Topic:Action recognition.\n",
      "Q:Is there a microphone? A:Yes Topic:Object detection.\n",
      "Q:How many microphones? A:1 Topic:Counting.\n",
      "Q:What color is the man's shirt? A:Blue Topic:Attribute classification.\n",
      "Q:What is hanging on the wall? A:Mirror Topic:Object detection.\n",
      "Q:What is he standing in front of? A:Screen Topic:Object detection.\n",
      "Q:Is he taller than the mirror? A:Unknown Topic:Comparative.\n",
      "Q:Where is the mirror hanging? A:Wall Topic:Position.\n",
      "Q:What is the shape of the mirror? A:Unknown Topic:Attribute classification.\n",
      "Q:How in the man feelining? A:Unknown Topic:Reasoning.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20cfae89-f06c-41f3-8e1b-d15996716c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatgpt(sub_df, idx, requirement, start_time):\n",
    "    caption_1 = list(sub_df[\"caption_1\"])\n",
    "    caption_2 = list(sub_df[\"caption_2\"])\n",
    "    prompt = requirement\n",
    "    for i, (c1,c2) in enumerate(zip(caption_1, caption_2)):\n",
    "        prompt += f\"\\nCase {i+1}\\n\"\n",
    "        prompt += f\"Description 1: {c1}\\n\"\n",
    "        prompt += f\"Description 2: {c2}\\n\"\n",
    "    \n",
    "    return prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "756879e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qa_generator(csv_path, requirement, demo = True):\n",
    "    start_time = time.time()\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if demo:\n",
    "        df = df[:9]\n",
    "    df = df[[\"id\", \"img\", \"caption_1\", \"caption_2\"]]\n",
    "    df = df.rename(columns={'id': 'img_id'})\n",
    "    df['id'] = df.index\n",
    "    df[\"caption_1\"] = df[\"caption_1\"].map(caption_processing)\n",
    "    df[\"caption_2\"] = df[\"caption_2\"].map(caption_processing)\n",
    "    df[\"img\"] = df[\"img\"].map(get_img_pth)\n",
    "    result_cases = []\n",
    "    for idx in range(int(len(df)/3)):\n",
    "        sub_df = df[idx*3:(idx+1)*3]\n",
    "        prompt = chatgpt(sub_df, idx, requirement, start_time)\n",
    "\n",
    "\n",
    "    return prompt\n",
    "\n",
    "result = qa_generator(\"clean_cartoon.csv\", requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4d990050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are given three cases with two different descriptions of an image each. You are required to ask 10 questions, their topics, and their answers based on the two descriptions for each case. The questions must be suitable for preschool students and should be about counting, reasoning, object detection, action recognition, attribute classification, comparative, spatial, or position. Morevoer, the type of question should be yes/no and open-end and the answer cannot be more than 3 word.\n",
      "case 0:\n",
      "Description 1: a man is standing in front of a large screen that is turned on he is wearing a blue shirt andblue headphones he is also wearing a purple shirt and a purple vest there is a large mirror on the wall behind the man.\n",
      "Description 2: a person is standing and he is wearing headphones on his head he is holding a microphone in his handhe is also wearing a blue tshirt and i can also see a microphone on the right side of the image there is a wall.\n",
      "case 0:\n",
      "Q:How many people are there? A:1 Topic:Counting.\n",
      "Q:What is the man doing? A:Standing Topic:Action recognition.\n",
      "Q:Is there a microphone? A:Yes Topic:Object detection.\n",
      "Q:How many microphones? A:1 Topic:Counting.\n",
      "Q:What color is the man's shirt? A:Blue Topic:Attribute classification.\n",
      "Q:What is hanging on the wall? A:Mirror Topic:Object detection.\n",
      "Q:What is he standing in front of? A:Screen Topic:Object detection.\n",
      "Q:Is he taller than the mirror? A:Unknown Topic:Comparative.\n",
      "Q:Where is the mirror hanging? A:Wall Topic:Position.\n",
      "Q:What is the shape of the mirror? A:Unknown Topic:Attribute classification.\n",
      "Q:How in the man feelining? A:Unknown Topic:Reasoning.\n",
      "\n",
      "Case 1\n",
      "Description 1: this image may contain human person electronics keyboard computer keyboard musical instrument and crowd. people skin is yellow.\n",
      "Description 2: a group of people are playing a game on the table in the background there are pictures frames on the wall. people skin is yellow.\n",
      "\n",
      "Case 2\n",
      "Description 1: this image may contain audience human crowd person speech and audience. people skin is yellow.\n",
      "Description 2: a group of people sitting on the benches and i can also see a person standing on the left side of the image in the background there is a door. people skin is yellow.\n",
      "\n",
      "Case 3\n",
      "Description 1: a man standing in front of a pile of junk the man is holding a can of soda in his hand the man has a large pile of garbage behind him there are cars parked in the pile of trash there is a tree in the background there are white clouds in the sky. people skin is yellow.\n",
      "Description 2: a person standing and holding a cup in his hand and he is wearing a red tshirt and blue pant and i can also see a red color car in the background there are buildings trees sky and clouds. people skin is yellow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "720a5546-fd31-4372-8df4-878aae5c7282",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_questions_anwers(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed2e406c-eb60-4c87-930c-32682399a00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1:\n",
      "Q:How many people are there? A:Unknown Topic:Counting.\n",
      "Q:What are they playing? A:Game Topic:Object detection.\n",
      "Q:Are there any pictures? A:Yes Topic:Object detection.\n",
      "Q:What color is their skin? A:Yellow Topic:Attribute classification.\n",
      "Q:Is there a musical instrument? A:Unknown Topic:Object detection.\n",
      "Q:What is on the table? A:Game Topic:Object detection.\n",
      "Q:How many frames on the wall? A:Unknown Topic:Counting.\n",
      "Q:What is the background color? A:Unknown Topic:Attribute classification.\n",
      "Q:What is the location of the frames? A:Wall Topic:Position.\n",
      "Q:What is the game about? A:Unknown Topic:Reasoning.\n",
      "\n",
      "Case 2:\n",
      "Q:How many people? A:Multiple Topic:Counting.\n",
      "Q:Are they sitting or standing? A:Sitting/standing Topic:Action recognition.\n",
      "Q:What is in the background? A:Door Topic:Object detection.\n",
      "Q:What color is their skin? A:Yellow Topic:Attribute classification.\n",
      "Q:What are they listening to? A:Speech Topic:Object detection.\n",
      "Q:What is the audience doing? A:Sitting Topic:Action recognition.\n",
      "Q:What is the event they are attending? A:Unknown Topic:Reasoning.\n",
      "Q:Where is the location of the event? A:Unknown Topic:Position.\n",
      "Q:How many benches are there? A:Unknown Topic:Counting.\n",
      "Q:Who is the person standing? A:Unknown Topic:Reasoning.\n",
      "\n",
      "Case 3:\n",
      "Q:What is the man holding? A:Soda can Topic:Object detection.\n",
      "Q:What is behind the man? A:Pile of garbage Topic:Object detection.\n",
      "Q:How many cars are there? A:Multiple Topic:Counting.\n",
      "Q:What color is the man's shirt? A:Red Topic:Attribute classification.\n",
      "Q:What is the color of the car? A:Red Topic:Attribute classification.\n",
      "Q:What is the man doing? A:Standing Topic:Action recognition.\n",
      "Q:Where is the tree? A:Background Topic:Position.\n",
      "Q:What is in the sky? A:White clouds Topic:Object detection.\n",
      "Q:What is the condition of the pile of junk? A:Unknown Topic:Reasoning.\n",
      "Q:What is the location of the junk? A:Behind man Topic:Position.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fae6ca22-3413-436e-9016-878021567421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q:How many people are there? A:Unknown Topic:Counting.\n",
      "Q:What are they playing? A:Game Topic:Object detection.\n",
      "Q:Are there any pictures? A:Yes Topic:Object detection.\n",
      "Q:What color is their skin? A:Yellow Topic:Attribute classification.\n",
      "Q:Is there a musical instrument? A:Unknown Topic:Object detection.\n",
      "Q:What is on the table? A:Game Topic:Object detection.\n",
      "Q:How many frames on the wall? A:Unknown Topic:Counting.\n",
      "Q:What is the background color? A:Unknown Topic:Attribute classification.\n",
      "Q:What is the location of the frames? A:Wall Topic:Position.\n",
      "Q:What is the game about? A:Unknown Topic:Reasoning.\n",
      "\n",
      "['How many people are there? A:Unknown Topic:Counting.', 'What are they playing? A:Game Topic:Object detection.', 'Are there any pictures? A:Yes Topic:Object detection.', 'What color is their skin? A:Yellow Topic:Attribute classification.', 'Is there a musical instrument? A:Unknown Topic:Object detection.', 'What is on the table? A:Game Topic:Object detection.', 'How many frames on the wall? A:Unknown Topic:Counting.', 'What is the background color? A:Unknown Topic:Attribute classification.', 'What is the location of the frames? A:Wall Topic:Position.', 'What is the game about? A:Unknown Topic:Reasoning.\\n']\n",
      "\n",
      "Q:How many people? A:Multiple Topic:Counting.\n",
      "Q:Are they sitting or standing? A:Sitting/standing Topic:Action recognition.\n",
      "Q:What is in the background? A:Door Topic:Object detection.\n",
      "Q:What color is their skin? A:Yellow Topic:Attribute classification.\n",
      "Q:What are they listening to? A:Speech Topic:Object detection.\n",
      "Q:What is the audience doing? A:Sitting Topic:Action recognition.\n",
      "Q:What is the event they are attending? A:Unknown Topic:Reasoning.\n",
      "Q:Where is the location of the event? A:Unknown Topic:Position.\n",
      "Q:How many benches are there? A:Unknown Topic:Counting.\n",
      "Q:Who is the person standing? A:Unknown Topic:Reasoning.\n",
      "\n",
      "['How many people? A:Multiple Topic:Counting.', 'Are they sitting or standing? A:Sitting/standing Topic:Action recognition.', 'What is in the background? A:Door Topic:Object detection.', 'What color is their skin? A:Yellow Topic:Attribute classification.', 'What are they listening to? A:Speech Topic:Object detection.', 'What is the audience doing? A:Sitting Topic:Action recognition.', 'What is the event they are attending? A:Unknown Topic:Reasoning.', 'Where is the location of the event? A:Unknown Topic:Position.', 'How many benches are there? A:Unknown Topic:Counting.', 'Who is the person standing? A:Unknown Topic:Reasoning.\\n']\n",
      "\n",
      "Q:What is the man holding? A:Soda can Topic:Object detection.\n",
      "Q:What is behind the man? A:Pile of garbage Topic:Object detection.\n",
      "Q:How many cars are there? A:Multiple Topic:Counting.\n",
      "Q:What color is the man's shirt? A:Red Topic:Attribute classification.\n",
      "Q:What is the color of the car? A:Red Topic:Attribute classification.\n",
      "Q:What is the man doing? A:Standing Topic:Action recognition.\n",
      "Q:Where is the tree? A:Background Topic:Position.\n",
      "Q:What is in the sky? A:White clouds Topic:Object detection.\n",
      "Q:What is the condition of the pile of junk? A:Unknown Topic:Reasoning.\n",
      "Q:What is the location of the junk? A:Behind man Topic:Position.\n",
      "['What is the man holding? A:Soda can Topic:Object detection.', 'What is behind the man? A:Pile of garbage Topic:Object detection.', 'How many cars are there? A:Multiple Topic:Counting.', \"What color is the man's shirt? A:Red Topic:Attribute classification.\", 'What is the color of the car? A:Red Topic:Attribute classification.', 'What is the man doing? A:Standing Topic:Action recognition.', 'Where is the tree? A:Background Topic:Position.', 'What is in the sky? A:White clouds Topic:Object detection.', 'What is the condition of the pile of junk? A:Unknown Topic:Reasoning.', 'What is the location of the junk? A:Behind man Topic:Position.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'questions': ['How many people are there?',\n",
       "   'What are they playing?',\n",
       "   'Are there any pictures?',\n",
       "   'What color is their skin?',\n",
       "   'Is there a musical instrument?',\n",
       "   'What is on the table?',\n",
       "   'How many frames on the wall?',\n",
       "   'What is the background color?',\n",
       "   'What is the location of the frames?',\n",
       "   'What is the game about?'],\n",
       "  'answers': ['Unknown',\n",
       "   'Game',\n",
       "   'Yes',\n",
       "   'Yellow',\n",
       "   'Unknown',\n",
       "   'Game',\n",
       "   'Unknown',\n",
       "   'Unknown',\n",
       "   'Wall',\n",
       "   'Unknown'],\n",
       "  'topics': ['Counting.',\n",
       "   'Object detection.',\n",
       "   'Object detection.',\n",
       "   'Attribute classification.',\n",
       "   'Object detection.',\n",
       "   'Object detection.',\n",
       "   'Counting.',\n",
       "   'Attribute classification.',\n",
       "   'Position.',\n",
       "   'Reasoning.']},\n",
       " {'questions': ['How many people?',\n",
       "   'Are they sitting or standing?',\n",
       "   'What is in the background?',\n",
       "   'What color is their skin?',\n",
       "   'What are they listening to?',\n",
       "   'What is the audience doing?',\n",
       "   'What is the event they are attending?',\n",
       "   'Where is the location of the event?',\n",
       "   'How many benches are there?',\n",
       "   'Who is the person standing?'],\n",
       "  'answers': ['Multiple',\n",
       "   'Sitting/standing',\n",
       "   'Door',\n",
       "   'Yellow',\n",
       "   'Speech',\n",
       "   'Sitting',\n",
       "   'Unknown',\n",
       "   'Unknown',\n",
       "   'Unknown',\n",
       "   'Unknown'],\n",
       "  'topics': ['Counting.',\n",
       "   'Action recognition.',\n",
       "   'Object detection.',\n",
       "   'Attribute classification.',\n",
       "   'Object detection.',\n",
       "   'Action recognition.',\n",
       "   'Reasoning.',\n",
       "   'Position.',\n",
       "   'Counting.',\n",
       "   'Reasoning.']},\n",
       " {'questions': ['What is the man holding?',\n",
       "   'What is behind the man?',\n",
       "   'How many cars are there?',\n",
       "   \"What color is the man's shirt?\",\n",
       "   'What is the color of the car?',\n",
       "   'What is the man doing?',\n",
       "   'Where is the tree?',\n",
       "   'What is in the sky?',\n",
       "   'What is the condition of the pile of junk?',\n",
       "   'What is the location of the junk?'],\n",
       "  'answers': ['Soda can',\n",
       "   'Pile of garbage',\n",
       "   'Multiple',\n",
       "   'Red',\n",
       "   'Red',\n",
       "   'Standing',\n",
       "   'Background',\n",
       "   'White clouds',\n",
       "   'Unknown',\n",
       "   'Behind man'],\n",
       "  'topics': ['Object detection.',\n",
       "   'Object detection.',\n",
       "   'Counting.',\n",
       "   'Attribute classification.',\n",
       "   'Attribute classification.',\n",
       "   'Action recognition.',\n",
       "   'Position.',\n",
       "   'Object detection.',\n",
       "   'Reasoning.',\n",
       "   'Position.']}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_cases(string):\n",
    "    string = string.replace(\"For case\", \"Case\")\n",
    "    string = string.replace(\"For Case\", \"Case\")\n",
    "    string = string.replace(\"\\n\\n\", \"\\n\")\n",
    "    \n",
    "    cases = []\n",
    "    \n",
    "    # Split the string by 'Case' to separate each case\n",
    "    case_strings = string.split('Case ')[1:]\n",
    "    for case_string in case_strings:\n",
    "        case = {}\n",
    "        case_string= case_string[2:]\n",
    "        print(case_string)\n",
    "        # Split the case string by newline character '\\n' to separate each question-answer pair\n",
    "        pairs = case_string.split('\\nQ:')[1:]\n",
    "        print(pairs)\n",
    "        \n",
    "        case['questions'] = []\n",
    "        case['answers'] = []\n",
    "        case['topics'] = []\n",
    "        \n",
    "        for pair in pairs:\n",
    "            # Split the pair by 'Q:', 'A:', and 'Topic:' to extract the question, answer, and topic respectively\n",
    "            question, answer, topic = pair.split(' A:', 1)[0].strip(), pair.split(' A:', 1)[1].split(' Topic:', 1)[0].strip(), pair.split(' Topic:', 1)[1].strip()\n",
    "            \n",
    "            case['questions'].append(question)\n",
    "            case['answers'].append(answer)\n",
    "            case['topics'].append(topic)\n",
    "        \n",
    "        cases.append(case)\n",
    "    return cases\n",
    "extract_cases(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930c510-f436-4ce1-8384-6a6c87c14f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83a7213-cdd7-43cf-aff4-55c5d836283b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
